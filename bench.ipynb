{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ref import hadamard_transform_ref\n",
    "from fast_hadamard_transform import hadamard_transform\n",
    "from kernel import my_hadamard_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "              aten::copy_        62.49%      13.681ms       169.81%      37.178ms      12.393ms      21.196ms        96.79%      37.229ms      12.410ms             3  \n",
      "                 aten::to         0.09%      20.727us       136.32%      29.847ms      14.923ms      26.000us         0.12%      29.853ms      14.927ms             2  \n",
      "           aten::_to_copy         0.34%      75.326us       136.20%      29.820ms      14.910ms      56.000us         0.26%      29.827ms      14.914ms             2  \n",
      "             aten::linear         0.09%      20.465us         1.22%     266.083us     266.083us      20.000us         0.09%     307.000us     307.000us             1  \n",
      "             aten::matmul         0.06%      12.389us         0.84%     184.005us     184.005us      13.000us         0.06%     228.000us     228.000us             1  \n",
      "                 aten::mm         0.64%     139.385us         0.76%     166.874us     166.874us     215.000us         0.98%     215.000us     215.000us             1  \n",
      "            aten::reshape         0.21%      45.379us         0.47%     102.406us      51.203us      66.000us         0.30%     126.000us      63.000us             2  \n",
      "               aten::view         0.18%      40.365us         0.18%      40.365us      20.182us      60.000us         0.27%      60.000us      30.000us             2  \n",
      "                  aten::t         0.09%      19.687us         0.25%      55.445us      55.445us      23.000us         0.11%      59.000us      59.000us             1  \n",
      "      aten::empty_strided         0.21%      45.491us         0.21%      45.491us      22.745us      53.000us         0.24%      53.000us      26.500us             2  \n",
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 21.894ms\n",
      "Self CUDA time total: 21.898ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3241595/2726202886.py:3: FutureWarning: The attribute `use_cuda` will be deprecated soon, please use ``use_device = 'cuda'`` instead.\n",
      "  with torch.autograd.profiler.profile(use_cuda=True) as prof:\n"
     ]
    }
   ],
   "source": [
    "nelem = 4096\n",
    "x = torch.randn(nelem, dtype=torch.float32, device=\"cuda\")\n",
    "with torch.autograd.profiler.profile(use_cuda=True) as prof:\n",
    "    hadamard_transform_ref(x)\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "      HadamardTransformFn        38.11%      85.218us        89.09%     199.208us     199.208us     112.000us        54.63%     205.000us     205.000us             1  \n",
      "            aten::reshape         6.09%      13.626us        18.91%      42.295us      21.148us      24.000us        11.71%      52.000us      26.000us             2  \n",
      "         aten::empty_like         4.71%      10.527us        17.49%      39.099us      39.099us      13.000us         6.34%      41.000us      41.000us             1  \n",
      "               aten::view         9.85%      22.017us         9.85%      22.017us      11.008us      28.000us        13.66%      28.000us      14.000us             2  \n",
      "      aten::empty_strided        11.47%      25.644us        11.47%      25.644us      25.644us      28.000us        13.66%      28.000us      28.000us             1  \n",
      "          cudaEventRecord        17.07%      38.173us        17.07%      38.173us       2.727us       0.000us         0.00%       0.000us       0.000us            14  \n",
      "         cudaLaunchKernel         8.43%      18.844us         8.43%      18.844us      18.844us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "    cudaDeviceSynchronize         4.28%       9.565us         4.28%       9.565us       9.565us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 223.614us\n",
      "Self CUDA time total: 205.000us\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3241595/2756932586.py:1: FutureWarning: The attribute `use_cuda` will be deprecated soon, please use ``use_device = 'cuda'`` instead.\n",
      "  with torch.autograd.profiler.profile(use_cuda=True) as prof:\n"
     ]
    }
   ],
   "source": [
    "with torch.autograd.profiler.profile(use_cuda=True) as prof:\n",
    "   hadamard_transform(x)\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3241595/1350030213.py:1: FutureWarning: The attribute `use_cuda` will be deprecated soon, please use ``use_device = 'cuda'`` instead.\n",
      "  with torch.autograd.profiler.profile(use_cuda=True) as prof:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NotImplementedError' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.profiler.profile(use_cuda=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m prof:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mmy_hadamard_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: 'NotImplementedError' object is not callable"
     ]
    }
   ],
   "source": [
    "with torch.autograd.profiler.profile(use_cuda=True) as prof:\n",
    "    my_hadamard_transform(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tilelang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
