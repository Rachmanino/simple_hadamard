{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "479e372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kernel import hadamard\n",
    "import tilelang\n",
    "import tilelang.language as T\n",
    "# from fast_hadamard_transform import hadamard_transform\n",
    "from ref import hadamard_transform_ref\n",
    "import torch\n",
    "b, d, dtype = 1024, 8192, torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af401dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(b=1024, d=8192, dtype=torch.float32):\n",
    "    x = torch.rand(b, d, dtype=dtype, device='cuda')\n",
    "    fn = hadamard(b, d, dtype.__str__().split('.')[-1])\n",
    "    kernel = tilelang.compile(fn, out_idx=1, target='cuda')\n",
    "    return torch.allclose(kernel(x), hadamard_transform_ref(x), rtol=1e-2, atol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfeb6a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(d=8192)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a2672c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_331891/876011834.py:1: FutureWarning: The attribute `use_cuda` will be deprecated soon, please use ``use_device = 'cuda'`` instead.\n",
      "  with torch.autograd.profiler.profile(use_cuda=True) as prof:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'hadamard_transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.profiler.profile(use_cuda=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m prof:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mhadamard_transform\u001b[49m(A)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(prof.key_averages().table(sort_by=\u001b[33m\"\u001b[39m\u001b[33mcuda_time_total\u001b[39m\u001b[33m\"\u001b[39m, row_limit=\u001b[32m10\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'hadamard_transform' is not defined"
     ]
    }
   ],
   "source": [
    "with torch.autograd.profiler.profile(use_cuda=True) as prof:\n",
    "    hadamard_transform(A)\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ec59db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "              aten::empty         0.73%      19.481us         0.73%      19.481us      19.481us       3.000us       100.00%       3.000us       3.000us             1  \n",
      "          cudaEventRecord         0.35%       9.423us         0.35%       9.423us       4.711us       0.000us         0.00%       0.000us       0.000us             2  \n",
      "         cudaLaunchKernel         0.57%      15.173us         0.57%      15.173us      15.173us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "    cudaDeviceSynchronize        98.35%       2.624ms        98.35%       2.624ms       2.624ms       0.000us         0.00%       0.000us       0.000us             1  \n",
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.668ms\n",
      "Self CUDA time total: 3.000us\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_175088/790097636.py:1: FutureWarning: The attribute `use_cuda` will be deprecated soon, please use ``use_device = 'cuda'`` instead.\n",
      "  with torch.autograd.profiler.profile(use_cuda=True) as prof:\n"
     ]
    }
   ],
   "source": [
    "with torch.autograd.profiler.profile(use_cuda=True) as prof:\n",
    "    kernel(A)\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tilelang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
