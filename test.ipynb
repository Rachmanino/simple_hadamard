{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "479e372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kernel import hadamard\n",
    "import tilelang\n",
    "import tilelang.language as T\n",
    "from fast_hadamard_transform import hadamard_transform\n",
    "from ref import hadamard_transform_ref\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af401dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(b=1024, d=8192, dtype=torch.float32):\n",
    "    x = torch.rand(b, d, dtype=dtype, device='cuda')\n",
    "    fn = hadamard(b, d, dtype.__str__().split('.')[-1])\n",
    "    kernel = tilelang.compile(fn, out_idx=1, target='cuda')\n",
    "    print(f'Test for {d=} and {dtype=}:', end=' ')\n",
    "    if torch.allclose(\n",
    "        kernel(x), hadamard_transform(x), atol=1e-3, rtol=1e-3\n",
    "    ):\n",
    "        print('Passed')\n",
    "    else:\n",
    "        print('Failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfeb6a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for d=2 and dtype=torch.float32: Passed\n",
      "Test for d=4 and dtype=torch.float32: Passed\n",
      "Test for d=8 and dtype=torch.float32: Passed\n",
      "Test for d=16 and dtype=torch.float32: Passed\n",
      "Test for d=32 and dtype=torch.float32: Passed\n",
      "Test for d=64 and dtype=torch.float32: Passed\n",
      "Test for d=128 and dtype=torch.float32: Passed\n",
      "Test for d=256 and dtype=torch.float32: Passed\n",
      "Test for d=512 and dtype=torch.float32: Passed\n",
      "Test for d=1024 and dtype=torch.float32: Passed\n",
      "Test for d=2048 and dtype=torch.float32: Passed\n",
      "Test for d=4096 and dtype=torch.float32: Passed\n",
      "Test for d=8192 and dtype=torch.float32: Passed\n",
      "Test for d=16384 and dtype=torch.float32: Passed\n",
      "Test for d=32768 and dtype=torch.float32: Passed\n"
     ]
    }
   ],
   "source": [
    "for logd in range(1, 16):\n",
    "    d = 2 ** logd\n",
    "    test(d=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a2672c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "      HadamardTransformFn        34.86%     142.321us        86.71%     354.023us     354.023us     207.000us        56.10%     369.000us     369.000us             1  \n",
      "            aten::reshape         8.99%      36.712us        20.75%      84.723us      42.361us      45.000us        12.20%      84.000us      42.000us             2  \n",
      "         aten::empty_like         5.56%      22.695us        16.67%      68.069us      68.069us      32.000us         8.67%      78.000us      78.000us             1  \n",
      "      aten::empty_strided         8.82%      35.995us         8.82%      35.995us      35.995us      46.000us        12.47%      46.000us      46.000us             1  \n",
      "               aten::view         7.11%      29.024us         7.11%      29.024us      14.512us      39.000us        10.57%      39.000us      19.500us             2  \n",
      "          cudaEventRecord        23.19%      94.698us        23.19%      94.698us       6.764us       0.000us         0.00%       0.000us       0.000us            14  \n",
      "         cudaLaunchKernel         6.57%      26.830us         6.57%      26.830us      26.830us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "    cudaDeviceSynchronize         4.90%      20.000us         4.90%      20.000us      20.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 408.275us\n",
      "Self CUDA time total: 369.000us\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_414892/2190301601.py:2: FutureWarning: The attribute `use_cuda` will be deprecated soon, please use ``use_device = 'cuda'`` instead.\n",
      "  with torch.autograd.profiler.profile(use_cuda=True) as prof:\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1024, 8192, dtype=torch.float32, device='cuda')\n",
    "with torch.autograd.profiler.profile(use_cuda=True) as prof:\n",
    "    hadamard_transform(x)\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tilelang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
